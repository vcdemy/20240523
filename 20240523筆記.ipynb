{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da55d39e-9190-49da-9c28-17adcd0ebad6",
   "metadata": {},
   "source": [
    "# 20240523 筆記"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "312b7548-b669-491f-b5a1-b987ee4f80da",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 126] 找不到指定的模組。 Error loading \"C:\\Users\\Victor\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\lib\\shm.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\__init__.py:141\u001b[0m\n\u001b[0;32m    139\u001b[0m                 err \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mWinError(ctypes\u001b[38;5;241m.\u001b[39mget_last_error())\n\u001b[0;32m    140\u001b[0m                 err\u001b[38;5;241m.\u001b[39mstrerror \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Error loading \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdll\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or one of its dependencies.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 141\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    143\u001b[0m     kernel32\u001b[38;5;241m.\u001b[39mSetErrorMode(prev_error_mode)\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_preload_cuda_deps\u001b[39m(lib_folder, lib_name):\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 126] 找不到指定的模組。 Error loading \"C:\\Users\\Victor\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\lib\\shm.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4e15e1-046f-4266-b221-b314036a680d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f0302a-0a8d-4076-854a-fb4741c2ea38",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open('beattles.jpg')  # PIL image\n",
    "\n",
    "# Inference\n",
    "results = model(im, augment=True)  # batch of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de1e126-320b-4d51-8235-710b6e3ad88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde3eeab-ccb8-4d04-b77e-f2c1466aba32",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.pandas().xyxy[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2720ccfa-9f8b-44f0-8106-89f8c3a00f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = results.pandas().xyxy[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd71e5ee-fee8-4835-b71e-67a9e5c45b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.name == 'person'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c0bff7-b675-410d-870d-f263eb3f89ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.name == 'person']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2517def6-5f90-419c-88ae-82fa02c4e7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.name == 'person'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd54e07a-73dd-4723-aadd-649db707b3c9",
   "metadata": {},
   "source": [
    "## 使用 teachable machine 的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d110719f-b7ea-491a-a91f-6f570d218161",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model  # TensorFlow is required for Keras to work\n",
    "from PIL import Image, ImageOps  # Install pillow instead of PIL\n",
    "import numpy as np\n",
    "\n",
    "# Disable scientific notation for clarity\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "# Load the model\n",
    "model = load_model(\"keras_model.h5\", compile=False)\n",
    "\n",
    "# Load the labels\n",
    "class_names = open(\"labels.txt\", \"r\").readlines()\n",
    "\n",
    "# Create the array of the right shape to feed into the keras model\n",
    "# The 'length' or number of images you can put into the array is\n",
    "# determined by the first position in the shape tuple, in this case 1\n",
    "data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
    "\n",
    "# Replace this with the path to your image\n",
    "image = Image.open(\"magazine.webp\").convert(\"RGB\")\n",
    "\n",
    "# resizing the image to be at least 224x224 and then cropping from the center\n",
    "size = (224, 224)\n",
    "image = ImageOps.fit(image, size, Image.Resampling.LANCZOS)\n",
    "\n",
    "# turn the image into a numpy array\n",
    "image_array = np.asarray(image)\n",
    "\n",
    "# Normalize the image\n",
    "normalized_image_array = (image_array.astype(np.float32) / 127.5) - 1\n",
    "\n",
    "# Load the image into the array\n",
    "data[0] = normalized_image_array\n",
    "\n",
    "# Predicts the model\n",
    "prediction = model.predict(data)\n",
    "index = np.argmax(prediction)\n",
    "class_name = class_names[index]\n",
    "confidence_score = prediction[0][index]\n",
    "\n",
    "# Print prediction and confidence score\n",
    "print(\"Class:\", class_name[2:], end=\"\")\n",
    "print(\"Confidence Score:\", confidence_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa49bccb-5cd5-4837-80f9-a73166a79f7c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.16.1-cp312-cp312-win_amd64.whl.metadata (3.5 kB)\n",
      "Collecting tensorflow-intel==2.16.1 (from tensorflow)\n",
      "  Using cached tensorflow_intel-2.16.1-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\victor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\victor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\victor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\victor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\victor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\victor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\victor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\victor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\victor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\victor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\victor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\victor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\victor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (69.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\victor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\victor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\victor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.10.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\victor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\victor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.64.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\victor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\victor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.3)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\victor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\victor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\victor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\victor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\victor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\victor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\victor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\victor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\victor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\victor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\victor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\victor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\victor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\victor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\victor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\victor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.2)\n",
      "Using cached tensorflow-2.16.1-cp312-cp312-win_amd64.whl (2.1 kB)\n",
      "Using cached tensorflow_intel-2.16.1-cp312-cp312-win_amd64.whl (377.1 MB)\n",
      "Installing collected packages: tensorflow-intel, tensorflow\n",
      "Successfully installed tensorflow-2.16.1 tensorflow-intel-2.16.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87f65b29-8a7d-4b3d-8a63-340eec081ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model  # TensorFlow is required for Keras to work\n",
    "from PIL import Image, ImageOps  # Install pillow instead of PIL\n",
    "import numpy as np\n",
    "\n",
    "def process(image):\n",
    "  # Disable scientific notation for clarity\n",
    "  np.set_printoptions(suppress=True)\n",
    "\n",
    "  # Load the model\n",
    "  model = load_model(\"keras_model.h5\", compile=False)\n",
    "\n",
    "  # Load the labels\n",
    "  class_names = open(\"labels.txt\", \"r\").readlines()\n",
    "\n",
    "  # Create the array of the right shape to feed into the keras model\n",
    "  # The 'length' or number of images you can put into the array is\n",
    "  # determined by the first position in the shape tuple, in this case 1\n",
    "  data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
    "\n",
    "  # Replace this with the path to your image\n",
    "  # image = Image.open(\"result1.png\").convert(\"RGB\")\n",
    "\n",
    "  # resizing the image to be at least 224x224 and then cropping from the center\n",
    "  size = (224, 224)\n",
    "  image = ImageOps.fit(image, size, Image.Resampling.LANCZOS)\n",
    "\n",
    "  # turn the image into a numpy array\n",
    "  image_array = np.asarray(image)\n",
    "\n",
    "  # Normalize the image\n",
    "  normalized_image_array = (image_array.astype(np.float32) / 127.5) - 1\n",
    "\n",
    "  # Load the image into the array\n",
    "  data[0] = normalized_image_array\n",
    "\n",
    "  # Predicts the model\n",
    "  prediction = model.predict(data)\n",
    "  index = np.argmax(prediction)\n",
    "  class_name = class_names[index]\n",
    "  confidence_score = prediction[0][index]\n",
    "\n",
    "  # Print prediction and confidence score\n",
    "  print(\"Class:\", class_name[2:], end=\"\")\n",
    "  print(\"Confidence Score:\", confidence_score)\n",
    "  return class_name[2:], confidence_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c42fee7c-3ab0-4d4a-b1f0-38ad352c387c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7864\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 4.21.0, however version 4.29.0 is available, please upgrade.\n",
      "--------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Victor\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\ops\\operation.py\", line 208, in from_config\n",
      "    return cls(**config)\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Victor\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\depthwise_conv2d.py\", line 118, in __init__\n",
      "    super().__init__(\n",
      "  File \"C:\\Users\\Victor\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_depthwise_conv.py\", line 106, in __init__\n",
      "    super().__init__(\n",
      "  File \"C:\\Users\\Victor\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\layers\\layer.py\", line 264, in __init__\n",
      "    raise ValueError(\n",
      "ValueError: Unrecognized keyword arguments passed to DepthwiseConv2D: {'groups': 1}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Victor\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\gradio\\queueing.py\", line 501, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Victor\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\gradio\\route_utils.py\", line 253, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Victor\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\gradio\\blocks.py\", line 1695, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Victor\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\gradio\\blocks.py\", line 1235, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Victor\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Victor\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2144, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Victor\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\anyio\\_backends\\_asyncio.py\", line 851, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Victor\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\gradio\\utils.py\", line 692, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Victor\\AppData\\Local\\Temp\\ipykernel_3620\\506829008.py\", line 10, in process\n",
      "    model = load_model(\"keras_model.h5\", compile=False)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Victor\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\saving\\saving_api.py\", line 183, in load_model\n",
      "    return legacy_h5_format.load_model_from_hdf5(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Victor\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\legacy\\saving\\legacy_h5_format.py\", line 133, in load_model_from_hdf5\n",
      "    model = saving_utils.model_from_config(\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Victor\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\legacy\\saving\\saving_utils.py\", line 85, in model_from_config\n",
      "    return serialization.deserialize_keras_object(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Victor\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\legacy\\saving\\serialization.py\", line 495, in deserialize_keras_object\n",
      "    deserialized_obj = cls.from_config(\n",
      "                       ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Victor\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\models\\sequential.py\", line 333, in from_config\n",
      "    layer = saving_utils.model_from_config(\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Victor\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\legacy\\saving\\saving_utils.py\", line 85, in model_from_config\n",
      "    return serialization.deserialize_keras_object(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Victor\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\legacy\\saving\\serialization.py\", line 495, in deserialize_keras_object\n",
      "    deserialized_obj = cls.from_config(\n",
      "                       ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Victor\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\models\\sequential.py\", line 333, in from_config\n",
      "    layer = saving_utils.model_from_config(\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Victor\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\legacy\\saving\\saving_utils.py\", line 85, in model_from_config\n",
      "    return serialization.deserialize_keras_object(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Victor\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\legacy\\saving\\serialization.py\", line 495, in deserialize_keras_object\n",
      "    deserialized_obj = cls.from_config(\n",
      "                       ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Victor\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\models\\model.py\", line 517, in from_config\n",
      "    return functional_from_config(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Victor\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\models\\functional.py\", line 517, in functional_from_config\n",
      "    process_layer(layer_data)\n",
      "  File \"C:\\Users\\Victor\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\models\\functional.py\", line 497, in process_layer\n",
      "    layer = saving_utils.model_from_config(\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Victor\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\legacy\\saving\\saving_utils.py\", line 85, in model_from_config\n",
      "    return serialization.deserialize_keras_object(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Victor\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\legacy\\saving\\serialization.py\", line 504, in deserialize_keras_object\n",
      "    deserialized_obj = cls.from_config(cls_config)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Victor\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\ops\\operation.py\", line 210, in from_config\n",
      "    raise TypeError(\n",
      "TypeError: Error when deserializing class 'DepthwiseConv2D' using config={'name': 'expanded_conv_depthwise', 'trainable': True, 'dtype': 'float32', 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'linear', 'use_bias': False, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_regularizer': None, 'activity_regularizer': None, 'bias_constraint': None, 'depth_multiplier': 1, 'depthwise_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'depthwise_regularizer': None, 'depthwise_constraint': None}.\n",
      "\n",
      "Exception encountered: Unrecognized keyword arguments passed to DepthwiseConv2D: {'groups': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "gr.Interface(process,\n",
    "             gr.Image(type='pil'),\n",
    "             ['text','text']).launch(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c711cd-9dc1-4221-8649-0d5221d233e2",
   "metadata": {},
   "source": [
    "# 使用 Keras Applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fdad1a-eb1f-4e2d-b3e1-5a68132082ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0092ae67-4dbd-4eb9-b353-48d9ac9852d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c3ad3b-a332-4453-8369-7e2ea34383b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'cat.jpeg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaf825d-841d-4b93-bf4f-29a9c25db396",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = image.img_to_array(img)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d28a97-ab2f-4d22-a64b-aa45d9089bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.expand_dims(x, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba93704-171d-4017-a5e1-cfcca9e95ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dcb114-d69d-4fd3-8c3c-808b4f7b1b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = preprocess_input(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37aeb87-e57c-47be-a7b2-7c35c6c4adc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5342b2f0-50f7-4e0d-a9e6-8b271c2c07a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Predicted:', decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84185afc-09da-4258-ab45-89c393c50286",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f2587a-1f81-4809-835d-005cb638ea32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "model = ResNet50(weights='imagenet')\n",
    "\n",
    "def keras_app(image):\n",
    "  size = (224, 224)\n",
    "  image = ImageOps.fit(image, size, Image.Resampling.LANCZOS)\n",
    "  x = np.array(image)\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "  x = preprocess_input(x)\n",
    "  preds = model.predict(x)\n",
    "\n",
    "  return decode_predictions(preds, top=3)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511818d3-eab0-4aa2-9f1b-f139f8da3f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import MobileNetV2\n",
    "from keras.applications.mobilenet_v2 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "model = MobileNetV2()\n",
    "\n",
    "def keras_app(image):\n",
    "  size = (224, 224)\n",
    "  image = ImageOps.fit(image, size, Image.Resampling.LANCZOS)\n",
    "  x = np.array(image)\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "  x = preprocess_input(x)\n",
    "  preds = model.predict(x)\n",
    "\n",
    "  return decode_predictions(preds, top=3)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3b89fb-7c47-45f8-aca0-d784bbff3400",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.Interface(keras_app,\n",
    "             gr.Image(type=\"pil\"),\n",
    "             \"text\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a769fc0-2be8-4eec-af27-8be2601e217a",
   "metadata": {},
   "source": [
    "## Perspective Transforamtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f95a8a2-4bf1-4c5a-807b-f29ec05d39bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774e6806-00ce-4d94-8cff-b6fc4fcc8ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mag = Image.open('magazine.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1f8e46-6479-49c6-b1e3-9419865e4aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(mag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9b45af-b00c-4625-be18-5accfc7ede89",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = np.float32([[95,154],[383,42],[619,373],[300,524]])\n",
    "p2 = np.float32([[200,50],[480,50],[480,500],[200,500]])\n",
    "m = cv2.getPerspectiveTransform(p1,p2)\n",
    "\n",
    "img = np.array(mag)\n",
    "output = cv2.warpPerspective(img, m, mag.size)\n",
    "\n",
    "px.imshow(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e7831d-59f2-4e2b-a511-cd62c82f02ba",
   "metadata": {},
   "source": [
    "## 作業 01\n",
    "\n",
    "請使用 YOLO 計算底下圖片上面的車子的數量。\n",
    "\n",
    "https://cdn.vox-cdn.com/thumbor/giGrFCisfuAEMvU7er0u-BI2ZxU=/0x0:5184x3669/925x925/filters:focal(2178x1421:3006x2249):format(webp)/cdn.vox-cdn.com/uploads/chorus_image/image/63923063/shutterstock_737258473.0.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c914dedf-f36b-4af8-a45b-80a178c0caea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
